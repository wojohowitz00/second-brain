---
phase: 06-processing-integration
plan: 03
type: execute
wave: 3
depends_on: ["06-02"]
files_modified:
  - backend/_scripts/process_inbox.py
  - backend/tests/test_process_inbox.py
autonomous: true

must_haves:
  truths:
    - "App processes backlog on startup (messages since last_ts)"
    - "App polls Slack every 2 minutes when running in daemon mode"
    - "Graceful shutdown on SIGTERM/SIGINT"
    - "End-to-end: Slack message -> classified -> filed in vault within one poll cycle"
  artifacts:
    - path: "backend/_scripts/process_inbox.py"
      provides: "Complete processing pipeline with polling loop"
      contains: "def main_loop"
      min_lines: 150
    - path: "backend/tests/test_process_inbox.py"
      provides: "Integration tests for processing pipeline"
      min_lines: 80
  key_links:
    - from: "backend/_scripts/process_inbox.py"
      to: "slack_client.fetch_messages"
      via: "import and call"
      pattern: "from slack_client import fetch_messages"
    - from: "backend/_scripts/process_inbox.py"
      to: "message_classifier.MessageClassifier"
      via: "import and instantiate"
      pattern: "get_classifier\\(\\)"
---

<objective>
Add polling loop capability to process_inbox.py and create integration tests for the end-to-end processing pipeline.

Purpose: Enable continuous operation with 2-minute polling intervals and graceful shutdown, completing the processing integration requirements.

Output: Updated process_inbox.py with main_loop() for daemon mode, plus integration tests verifying the complete Slack-to-vault flow.
</objective>

<execution_context>
@/Users/richardyu/.claude/get-shit-done/workflows/execute-plan.md
@/Users/richardyu/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-processing-integration/06-RESEARCH.md
@.planning/phases/06-processing-integration/06-01-SUMMARY.md
@.planning/phases/06-processing-integration/06-02-SUMMARY.md
@backend/_scripts/process_inbox.py
@backend/tests/conftest.py
@backend/tests/test_integration.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add signal handling and polling loop</name>
  <files>backend/_scripts/process_inbox.py</files>
  <action>
    Add polling loop with graceful shutdown to process_inbox.py:

    1. Add imports at top:
       ```python
       import signal
       import time
       import argparse
       ```

    2. Add shutdown flag and signal handler:
       ```python
       # Graceful shutdown flag
       _shutdown_requested = False

       def _signal_handler(sig, frame):
           """Handle shutdown signals gracefully."""
           global _shutdown_requested
           print(f"\nShutdown signal received ({signal.Signals(sig).name}), finishing current cycle...")
           _shutdown_requested = True

       # Register signal handlers
       signal.signal(signal.SIGTERM, _signal_handler)
       signal.signal(signal.SIGINT, _signal_handler)
       ```

    3. Add main_loop() function for daemon mode:
       ```python
       POLL_INTERVAL_SECONDS = 120  # 2 minutes

       def main_loop():
           """
           Run continuous processing loop with 2-minute polling interval.

           Handles graceful shutdown on SIGTERM/SIGINT.
           """
           global _shutdown_requested
           print(f"Starting processing loop (polling every {POLL_INTERVAL_SECONDS}s)...")

           while not _shutdown_requested:
               try:
                   process_all()
               except Exception as e:
                   print(f"Error in processing cycle: {e}")
                   # Continue running despite errors

               # Sleep in small increments to check shutdown flag
               for _ in range(POLL_INTERVAL_SECONDS):
                   if _shutdown_requested:
                       break
                   time.sleep(1)

           print("Graceful shutdown complete")
       ```

    4. Update if __name__ == "__main__" block:
       ```python
       if __name__ == "__main__":
           parser = argparse.ArgumentParser(description="Process Slack inbox messages")
           parser.add_argument("--daemon", "-d", action="store_true",
                             help="Run in daemon mode with 2-minute polling")
           parser.add_argument("--once", action="store_true",
                             help="Process once and exit (default)")
           args = parser.parse_args()

           if args.daemon:
               main_loop()
           else:
               process_all()
       ```
  </action>
  <verify>
    ```bash
    cd /Users/richardyu/PARA/Personal/1_Projects/apps/second-brain/backend/_scripts

    # Test CLI help
    python process_inbox.py --help

    # Test module loads with new functions
    python -c "from process_inbox import main_loop, POLL_INTERVAL_SECONDS; print('OK')"
    ```
  </verify>
  <done>process_inbox.py has main_loop() with signal handling and --daemon flag</done>
</task>

<task type="auto">
  <name>Task 2: Create integration tests for processing pipeline</name>
  <files>backend/tests/test_process_inbox.py</files>
  <action>
    Create test_process_inbox.py with integration tests:

    ```python
    """
    Integration tests for process_inbox module.

    Tests the end-to-end flow from Slack message to vault file.
    """

    import pytest
    from pathlib import Path
    from unittest.mock import Mock, patch, MagicMock
    from datetime import datetime

    # Test imports
    import sys
    sys.path.insert(0, str(Path(__file__).parent.parent / "_scripts"))

    from process_inbox import (
        process_message,
        process_all,
        get_classifier,
        fetch_new_messages,
        POLL_INTERVAL_SECONDS,
    )
    from message_classifier import ClassificationResult


    class TestProcessMessage:
        """Tests for process_message function."""

        def test_skips_fix_commands(self):
            """fix: commands should be skipped (handled by fix_handler)."""
            msg = {"text": "fix: Personal", "ts": "1234567890.123456"}
            result = process_message(msg)
            assert result is True  # Skipped, not failed

        def test_skips_already_processed(self, temp_state_dir):
            """Already processed messages should be skipped."""
            from state import mark_message_processed

            ts = "1234567890.123456"
            mark_message_processed(ts)

            msg = {"text": "Test message", "ts": ts}
            result = process_message(msg)
            assert result is True  # Skipped, not failed

        @patch("process_inbox.get_classifier")
        @patch("process_inbox.create_note_file")
        @patch("process_inbox.reply_to_message")
        def test_processes_new_message(
            self, mock_reply, mock_create, mock_get_classifier, temp_state_dir, tmp_path
        ):
            """New messages should be classified and filed."""
            # Setup mock classifier
            mock_classifier = Mock()
            mock_classifier.classify.return_value = ClassificationResult(
                domain="Personal",
                para_type="1_Projects",
                subject="apps",
                category="task",
                confidence=0.85,
                reasoning="Test"
            )
            mock_get_classifier.return_value = mock_classifier

            # Setup mock file creation
            mock_file = tmp_path / "test.md"
            mock_file.write_text("test")
            mock_create.return_value = mock_file

            msg = {"text": "Work on the app", "ts": "1234567890.123456"}
            result = process_message(msg)

            assert result is True
            mock_classifier.classify.assert_called_once_with("Work on the app")
            mock_create.assert_called_once()
            mock_reply.assert_called_once()

        @patch("process_inbox.get_classifier")
        @patch("process_inbox.reply_to_message")
        def test_low_confidence_not_filed(
            self, mock_reply, mock_get_classifier, temp_state_dir
        ):
            """Low confidence messages should not be filed."""
            mock_classifier = Mock()
            mock_classifier.classify.return_value = ClassificationResult(
                domain="Personal",
                para_type="3_Resources",
                subject="general",
                category="reference",
                confidence=0.4,  # Below 0.6 threshold
                reasoning="Uncertain"
            )
            mock_get_classifier.return_value = mock_classifier

            msg = {"text": "Ambiguous message", "ts": "1234567890.123456"}
            result = process_message(msg)

            assert result is True
            # Should reply with low confidence warning
            mock_reply.assert_called_once()
            call_text = mock_reply.call_args[0][1]
            assert "confidence" in call_text.lower()


    class TestProcessAll:
        """Tests for process_all function."""

        @patch("process_inbox.fetch_new_messages")
        @patch("process_inbox.process_message")
        @patch("process_inbox.record_successful_run")
        def test_processes_messages_oldest_first(
            self, mock_record, mock_process, mock_fetch, temp_state_dir
        ):
            """Messages should be processed oldest first."""
            mock_fetch.return_value = [
                {"text": "newer", "ts": "1234567892.0"},
                {"text": "older", "ts": "1234567890.0"},
            ]
            mock_process.return_value = True

            process_all()

            # Verify oldest processed first
            calls = mock_process.call_args_list
            assert len(calls) == 2
            assert calls[0][0][0]["text"] == "older"
            assert calls[1][0][0]["text"] == "newer"

        @patch("process_inbox.fetch_new_messages")
        @patch("process_inbox.record_successful_run")
        def test_handles_empty_inbox(self, mock_record, mock_fetch, temp_state_dir):
            """Empty inbox should record successful run."""
            mock_fetch.return_value = []

            process_all()

            mock_record.assert_called_once()


    class TestPollingConfig:
        """Tests for polling configuration."""

        def test_poll_interval_is_two_minutes(self):
            """Poll interval should be 120 seconds (2 minutes)."""
            assert POLL_INTERVAL_SECONDS == 120


    class TestGetClassifier:
        """Tests for lazy classifier initialization."""

        @patch("process_inbox.MessageClassifier")
        def test_creates_classifier_once(self, mock_class):
            """Classifier should be created once and reused."""
            import process_inbox
            process_inbox._classifier = None  # Reset singleton

            mock_instance = Mock()
            mock_class.return_value = mock_instance

            c1 = get_classifier()
            c2 = get_classifier()

            assert c1 is c2
            mock_class.assert_called_once()
    ```

    Key test patterns:
    - Use temp_state_dir fixture for state isolation
    - Mock external dependencies (Slack, file creation, classifier)
    - Test message ordering (oldest first)
    - Test skip conditions (fix:, already processed)
    - Test confidence threshold behavior
  </action>
  <verify>
    ```bash
    cd /Users/richardyu/PARA/Personal/1_Projects/apps/second-brain/backend
    pytest tests/test_process_inbox.py -v
    ```
  </verify>
  <done>Integration tests pass, covering message processing, ordering, and skip conditions</done>
</task>

<task type="auto">
  <name>Task 3: Verify end-to-end with manual test</name>
  <files>backend/_scripts/process_inbox.py</files>
  <action>
    Create a simple manual verification script to test the full pipeline:

    1. Create a test script (not committed, just for verification):
       ```python
       # test_e2e.py - run manually to verify
       import sys
       sys.path.insert(0, "backend/_scripts")

       from message_classifier import MessageClassifier
       from file_writer import create_note_file
       from pathlib import Path
       import tempfile

       # Test classification
       classifier = MessageClassifier()
       result = classifier.classify("Set up my home office workspace")
       print(f"Classification: {result.domain}/{result.para_type}/{result.subject} [{result.category}]")
       print(f"Confidence: {result.confidence:.0%}")
       print(f"Reasoning: {result.reasoning}")

       # Test file creation in temp dir
       with tempfile.TemporaryDirectory() as tmpdir:
           vault = Path(tmpdir)
           filepath = create_note_file(result, "Set up my home office workspace", vault)
           print(f"\nCreated file: {filepath}")
           print(f"Content:\n{filepath.read_text()}")
       ```

    2. Run the test script to verify the integration works:
       ```bash
       cd /Users/richardyu/PARA/Personal/1_Projects/apps/second-brain
       python test_e2e.py
       ```

    3. Verify output shows:
       - Classification with all 4 levels
       - File created in correct folder structure
       - Frontmatter with all required fields

    4. Delete the test script after verification.
  </action>
  <verify>
    ```bash
    cd /Users/richardyu/PARA/Personal/1_Projects/apps/second-brain/backend

    # Run all tests to ensure nothing is broken
    pytest tests/ -v --ignore=tests/test_integration.py -k "not integration"

    # Note: Skip live integration tests that require actual Slack/Ollama
    ```
  </verify>
  <done>End-to-end flow verified: classification -> file creation works correctly</done>
</task>

</tasks>

<verification>
```bash
cd /Users/richardyu/PARA/Personal/1_Projects/apps/second-brain/backend

# Run all processing tests
pytest tests/test_process_inbox.py -v

# Verify CLI works
python _scripts/process_inbox.py --help

# Check daemon mode flag exists (don't run, just verify)
python -c "from _scripts.process_inbox import main_loop; print('Daemon mode available')"
```

Tests pass, CLI has --daemon flag, module imports cleanly.
</verification>

<success_criteria>
1. process_inbox.py has main_loop() function for daemon mode
2. --daemon flag enables 2-minute polling
3. Signal handlers for SIGTERM/SIGINT enable graceful shutdown
4. test_process_inbox.py has 8+ test cases
5. All tests pass
6. End-to-end flow verified (classification -> file creation)
</success_criteria>

<output>
After completion, create `.planning/phases/06-processing-integration/06-03-SUMMARY.md`
</output>
